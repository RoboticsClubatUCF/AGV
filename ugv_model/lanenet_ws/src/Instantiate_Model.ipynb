{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAstepkmcYRl",
        "outputId": "9a85480e-b0cc-481d-f21c-63655ec44444",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'lanenet-lane-detection-pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IrohXu/lanenet-lane-detection-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdIh-qQSXaAM",
        "outputId": "0e24f797-2b08-4be0-cae4-ca8a63812906",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/jetson/lanenet_ws/src/lanenet-lane-detection-pytorch\n"
          ]
        }
      ],
      "source": [
        "cd lanenet-lane-detection-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lc-pVnrWcj_1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from model.lanenet.loss import DiscriminativeLoss\n",
        "from model.lanenet.backbone.UNet import UNet_Encoder, UNet_Decoder\n",
        "from model.lanenet.backbone.ENet import ENet_Encoder, ENet_Decoder\n",
        "#from model.lanenet.backbone.deeplabv3_plus.deeplabv3plus import Deeplabv3plus_Encoder, Deeplabv3plus_Decoder\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "class LaneNet(nn.Module):\n",
        "    def __init__(self, in_ch = 3, arch=\"ENet\"):\n",
        "        super(LaneNet, self).__init__()\n",
        "        # no of instances for segmentation\n",
        "        self.no_of_instances = 3  # if you want to output RGB instance map, it should be 3.\n",
        "        print(\"Use {} as backbone\".format(arch))\n",
        "        self._arch = arch\n",
        "        if self._arch == 'UNet':\n",
        "            self._encoder = UNet_Encoder(in_ch)\n",
        "            self._encoder.to(DEVICE)\n",
        "\n",
        "            self._decoder_binary = UNet_Decoder(2)\n",
        "            self._decoder_instance = UNet_Decoder(self.no_of_instances)\n",
        "            self._decoder_binary.to(DEVICE)\n",
        "            self._decoder_instance.to(DEVICE)\n",
        "        elif self._arch == 'ENet':\n",
        "            self._encoder = ENet_Encoder(in_ch)\n",
        "            self._encoder.to(DEVICE)\n",
        "\n",
        "            self._decoder_binary = ENet_Decoder(2)\n",
        "            self._decoder_instance = ENet_Decoder(self.no_of_instances)\n",
        "            self._decoder_binary.to(DEVICE)\n",
        "            self._decoder_instance.to(DEVICE)\n",
        "        elif self._arch == 'DeepLabv3+':\n",
        "            self._encoder = Deeplabv3plus_Encoder()\n",
        "            self._encoder.to(DEVICE)\n",
        "\n",
        "            self._decoder_binary = Deeplabv3plus_Decoder(2)\n",
        "            self._decoder_instance = Deeplabv3plus_Decoder(self.no_of_instances)\n",
        "            self._decoder_binary.to(DEVICE)\n",
        "            self._decoder_instance.to(DEVICE)\n",
        "        else:\n",
        "            raise(\"Please select right model.\")\n",
        "\n",
        "        self.relu = nn.ReLU().to(DEVICE)\n",
        "        self.sigmoid = nn.Sigmoid().to(DEVICE)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        if self._arch == 'UNet':\n",
        "            c1, c2, c3, c4, c5 = self._encoder(input_tensor)\n",
        "            binary = self._decoder_binary(c1, c2, c3, c4, c5)\n",
        "            instance = self._decoder_instance(c1, c2, c3, c4, c5)\n",
        "        elif self._arch == 'ENet':\n",
        "            c = self._encoder(input_tensor)\n",
        "            binary = self._decoder_binary(c)\n",
        "            instance = self._decoder_instance(c)\n",
        "        elif self._arch == 'DeepLabv3+':\n",
        "            c1, c2 = self._encoder(input_tensor)\n",
        "            binary = self._decoder_binary(c1, c2)\n",
        "            instance = self._decoder_instance(c1, c2)\n",
        "        else:\n",
        "            raise(\"Please select right model.\")\n",
        "\n",
        "        binary_seg_ret = torch.argmax(F.softmax(binary, dim=1), dim=1, keepdim=True)\n",
        "\n",
        "        pix_embedding = self.sigmoid(instance)\n",
        "\n",
        "        return {\n",
        "            'instance_seg_logits': pix_embedding,\n",
        "            'binary_seg_pred': binary_seg_ret,\n",
        "            'binary_seg_logits': binary\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpOiIbZHdIxg",
        "outputId": "d1b35033-2bf2-4f68-d99b-be99d154a858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use ENet as backbone\n"
          ]
        }
      ],
      "source": [
        "model = LaneNet(in_ch=3, arch=\"ENet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccqZHWUbkMW9",
        "outputId": "0ebfa74e-a6dd-4cce-d5b8-be228d0c6ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LaneNet(\n",
            "  (_encoder): ENet_Encoder(\n",
            "    (initial_block): InitialBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(3, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "      )\n",
            "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (bottleneck1_0): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(16, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck1_1): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck1_2): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck1_3): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck1_4): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck2_0): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck2_1): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck2_2): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck2_3): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
            "        (4): Conv2d(128, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
            "        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (6): PReLU(num_parameters=1)\n",
            "        (7): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (9): PReLU(num_parameters=1)\n",
            "        (10): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck2_4): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck2_5): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck2_6): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck2_7): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
            "        (4): Conv2d(128, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
            "        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (6): PReLU(num_parameters=1)\n",
            "        (7): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (9): PReLU(num_parameters=1)\n",
            "        (10): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck2_8): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck3_0): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck3_1): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck3_2): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
            "        (4): Conv2d(128, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
            "        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (6): PReLU(num_parameters=1)\n",
            "        (7): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (9): PReLU(num_parameters=1)\n",
            "        (10): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck3_3): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck3_4): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck3_5): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck3_6): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
            "        (4): Conv2d(128, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
            "        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (6): PReLU(num_parameters=1)\n",
            "        (7): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (9): PReLU(num_parameters=1)\n",
            "        (10): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck3_7): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (_decoder_binary): ENet_Decoder(\n",
            "    (bottleneck4_0): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (maxunpool): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "      )\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck4_1): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck4_2): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck5_0): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (maxunpool): Sequential(\n",
            "        (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "      )\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
            "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck5_1): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (fullconv): ConvTranspose2d(16, 2, kernel_size=(2, 2), stride=(2, 2))\n",
            "  )\n",
            "  (_decoder_instance): ENet_Decoder(\n",
            "    (bottleneck4_0): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (maxunpool): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "      )\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck4_1): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck4_2): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck5_0): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (maxunpool): Sequential(\n",
            "        (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "      )\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
            "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck5_1): BottleneckModule(\n",
            "      (activate): PReLU(num_parameters=1)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): PReLU(num_parameters=1)\n",
            "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): PReLU(num_parameters=1)\n",
            "        (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): PReLU(num_parameters=1)\n",
            "        (9): Dropout2d(p=0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (fullconv): ConvTranspose2d(16, 3, kernel_size=(2, 2), stride=(2, 2))\n",
            "  )\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvYvbiAgeIm4",
        "outputId": "7e90e211-fc1b-4217-cb5d-f00be4e86ed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 13, 32, 32]             364\n",
            "       BatchNorm2d-2           [-1, 13, 32, 32]              26\n",
            "             PReLU-3           [-1, 13, 32, 32]               1\n",
            "         MaxPool2d-4            [-1, 3, 32, 32]               0\n",
            "      InitialBlock-5           [-1, 16, 32, 32]               0\n",
            "            Conv2d-6           [-1, 64, 16, 16]           4,160\n",
            "       BatchNorm2d-7           [-1, 64, 16, 16]             128\n",
            "             PReLU-8           [-1, 64, 16, 16]               1\n",
            "            Conv2d-9           [-1, 64, 16, 16]          36,928\n",
            "      BatchNorm2d-10           [-1, 64, 16, 16]             128\n",
            "            PReLU-11           [-1, 64, 16, 16]               1\n",
            "           Conv2d-12           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
            "            PReLU-14           [-1, 64, 16, 16]               1\n",
            "        Dropout2d-15           [-1, 64, 16, 16]               0\n",
            "        MaxPool2d-16           [-1, 16, 16, 16]               0\n",
            "            PReLU-17           [-1, 64, 16, 16]               1\n",
            " BottleneckModule-18           [-1, 64, 16, 16]               0\n",
            "           Conv2d-19           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-20           [-1, 64, 16, 16]             128\n",
            "            PReLU-21           [-1, 64, 16, 16]               1\n",
            "           Conv2d-22           [-1, 64, 16, 16]          36,928\n",
            "      BatchNorm2d-23           [-1, 64, 16, 16]             128\n",
            "            PReLU-24           [-1, 64, 16, 16]               1\n",
            "           Conv2d-25           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-26           [-1, 64, 16, 16]             128\n",
            "            PReLU-27           [-1, 64, 16, 16]               1\n",
            "        Dropout2d-28           [-1, 64, 16, 16]               0\n",
            "            PReLU-29           [-1, 64, 16, 16]               1\n",
            " BottleneckModule-30           [-1, 64, 16, 16]               0\n",
            "           Conv2d-31           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-32           [-1, 64, 16, 16]             128\n",
            "            PReLU-33           [-1, 64, 16, 16]               1\n",
            "           Conv2d-34           [-1, 64, 16, 16]          36,928\n",
            "      BatchNorm2d-35           [-1, 64, 16, 16]             128\n",
            "            PReLU-36           [-1, 64, 16, 16]               1\n",
            "           Conv2d-37           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-38           [-1, 64, 16, 16]             128\n",
            "            PReLU-39           [-1, 64, 16, 16]               1\n",
            "        Dropout2d-40           [-1, 64, 16, 16]               0\n",
            "            PReLU-41           [-1, 64, 16, 16]               1\n",
            " BottleneckModule-42           [-1, 64, 16, 16]               0\n",
            "           Conv2d-43           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-44           [-1, 64, 16, 16]             128\n",
            "            PReLU-45           [-1, 64, 16, 16]               1\n",
            "           Conv2d-46           [-1, 64, 16, 16]          36,928\n",
            "      BatchNorm2d-47           [-1, 64, 16, 16]             128\n",
            "            PReLU-48           [-1, 64, 16, 16]               1\n",
            "           Conv2d-49           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-50           [-1, 64, 16, 16]             128\n",
            "            PReLU-51           [-1, 64, 16, 16]               1\n",
            "        Dropout2d-52           [-1, 64, 16, 16]               0\n",
            "            PReLU-53           [-1, 64, 16, 16]               1\n",
            " BottleneckModule-54           [-1, 64, 16, 16]               0\n",
            "           Conv2d-55           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-56           [-1, 64, 16, 16]             128\n",
            "            PReLU-57           [-1, 64, 16, 16]               1\n",
            "           Conv2d-58           [-1, 64, 16, 16]          36,928\n",
            "      BatchNorm2d-59           [-1, 64, 16, 16]             128\n",
            "            PReLU-60           [-1, 64, 16, 16]               1\n",
            "           Conv2d-61           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-62           [-1, 64, 16, 16]             128\n",
            "            PReLU-63           [-1, 64, 16, 16]               1\n",
            "        Dropout2d-64           [-1, 64, 16, 16]               0\n",
            "            PReLU-65           [-1, 64, 16, 16]               1\n",
            " BottleneckModule-66           [-1, 64, 16, 16]               0\n",
            "           Conv2d-67            [-1, 128, 8, 8]          32,896\n",
            "      BatchNorm2d-68            [-1, 128, 8, 8]             256\n",
            "            PReLU-69            [-1, 128, 8, 8]               1\n",
            "           Conv2d-70            [-1, 128, 8, 8]         147,584\n",
            "      BatchNorm2d-71            [-1, 128, 8, 8]             256\n",
            "            PReLU-72            [-1, 128, 8, 8]               1\n",
            "           Conv2d-73            [-1, 128, 8, 8]          16,512\n",
            "      BatchNorm2d-74            [-1, 128, 8, 8]             256\n",
            "            PReLU-75            [-1, 128, 8, 8]               1\n",
            "        Dropout2d-76            [-1, 128, 8, 8]               0\n",
            "        MaxPool2d-77             [-1, 64, 8, 8]               0\n",
            "            PReLU-78            [-1, 128, 8, 8]               1\n",
            " BottleneckModule-79            [-1, 128, 8, 8]               0\n",
            "           Conv2d-80            [-1, 128, 8, 8]          16,512\n",
            "      BatchNorm2d-81            [-1, 128, 8, 8]             256\n",
            "            PReLU-82            [-1, 128, 8, 8]               1\n",
            "           Conv2d-83            [-1, 128, 8, 8]         147,584\n",
            "      BatchNorm2d-84            [-1, 128, 8, 8]             256\n",
            "            PReLU-85            [-1, 128, 8, 8]               1\n",
            "           Conv2d-86            [-1, 128, 8, 8]          16,512\n",
            "      BatchNorm2d-87            [-1, 128, 8, 8]             256\n",
            "            PReLU-88            [-1, 128, 8, 8]               1\n",
            "        Dropout2d-89            [-1, 128, 8, 8]               0\n",
            "            PReLU-90            [-1, 128, 8, 8]               1\n",
            " BottleneckModule-91            [-1, 128, 8, 8]               0\n",
            "           Conv2d-92            [-1, 128, 8, 8]          16,512\n",
            "      BatchNorm2d-93            [-1, 128, 8, 8]             256\n",
            "            PReLU-94            [-1, 128, 8, 8]               1\n",
            "           Conv2d-95            [-1, 128, 8, 8]         147,584\n",
            "      BatchNorm2d-96            [-1, 128, 8, 8]             256\n",
            "            PReLU-97            [-1, 128, 8, 8]               1\n",
            "           Conv2d-98            [-1, 128, 8, 8]          16,512\n",
            "      BatchNorm2d-99            [-1, 128, 8, 8]             256\n",
            "           PReLU-100            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-101            [-1, 128, 8, 8]               0\n",
            "           PReLU-102            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-103            [-1, 128, 8, 8]               0\n",
            "          Conv2d-104            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-105            [-1, 128, 8, 8]             256\n",
            "           PReLU-106            [-1, 128, 8, 8]               1\n",
            "          Conv2d-107            [-1, 128, 8, 8]          82,048\n",
            "          Conv2d-108            [-1, 128, 8, 8]          82,048\n",
            "     BatchNorm2d-109            [-1, 128, 8, 8]             256\n",
            "           PReLU-110            [-1, 128, 8, 8]               1\n",
            "          Conv2d-111            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-112            [-1, 128, 8, 8]             256\n",
            "           PReLU-113            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-114            [-1, 128, 8, 8]               0\n",
            "           PReLU-115            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-116            [-1, 128, 8, 8]               0\n",
            "          Conv2d-117            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-118            [-1, 128, 8, 8]             256\n",
            "           PReLU-119            [-1, 128, 8, 8]               1\n",
            "          Conv2d-120            [-1, 128, 8, 8]         147,584\n",
            "     BatchNorm2d-121            [-1, 128, 8, 8]             256\n",
            "           PReLU-122            [-1, 128, 8, 8]               1\n",
            "          Conv2d-123            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-124            [-1, 128, 8, 8]             256\n",
            "           PReLU-125            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-126            [-1, 128, 8, 8]               0\n",
            "           PReLU-127            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-128            [-1, 128, 8, 8]               0\n",
            "          Conv2d-129            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-130            [-1, 128, 8, 8]             256\n",
            "           PReLU-131            [-1, 128, 8, 8]               1\n",
            "          Conv2d-132            [-1, 128, 8, 8]         147,584\n",
            "     BatchNorm2d-133            [-1, 128, 8, 8]             256\n",
            "           PReLU-134            [-1, 128, 8, 8]               1\n",
            "          Conv2d-135            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-136            [-1, 128, 8, 8]             256\n",
            "           PReLU-137            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-138            [-1, 128, 8, 8]               0\n",
            "           PReLU-139            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-140            [-1, 128, 8, 8]               0\n",
            "          Conv2d-141            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-142            [-1, 128, 8, 8]             256\n",
            "           PReLU-143            [-1, 128, 8, 8]               1\n",
            "          Conv2d-144            [-1, 128, 8, 8]         147,584\n",
            "     BatchNorm2d-145            [-1, 128, 8, 8]             256\n",
            "           PReLU-146            [-1, 128, 8, 8]               1\n",
            "          Conv2d-147            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-148            [-1, 128, 8, 8]             256\n",
            "           PReLU-149            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-150            [-1, 128, 8, 8]               0\n",
            "           PReLU-151            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-152            [-1, 128, 8, 8]               0\n",
            "          Conv2d-153            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-154            [-1, 128, 8, 8]             256\n",
            "           PReLU-155            [-1, 128, 8, 8]               1\n",
            "          Conv2d-156            [-1, 128, 8, 8]          82,048\n",
            "          Conv2d-157            [-1, 128, 8, 8]          82,048\n",
            "     BatchNorm2d-158            [-1, 128, 8, 8]             256\n",
            "           PReLU-159            [-1, 128, 8, 8]               1\n",
            "          Conv2d-160            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-161            [-1, 128, 8, 8]             256\n",
            "           PReLU-162            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-163            [-1, 128, 8, 8]               0\n",
            "           PReLU-164            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-165            [-1, 128, 8, 8]               0\n",
            "          Conv2d-166            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-167            [-1, 128, 8, 8]             256\n",
            "           PReLU-168            [-1, 128, 8, 8]               1\n",
            "          Conv2d-169            [-1, 128, 8, 8]         147,584\n",
            "     BatchNorm2d-170            [-1, 128, 8, 8]             256\n",
            "           PReLU-171            [-1, 128, 8, 8]               1\n",
            "          Conv2d-172            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-173            [-1, 128, 8, 8]             256\n",
            "           PReLU-174            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-175            [-1, 128, 8, 8]               0\n",
            "           PReLU-176            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-177            [-1, 128, 8, 8]               0\n",
            "          Conv2d-178            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-179            [-1, 128, 8, 8]             256\n",
            "           PReLU-180            [-1, 128, 8, 8]               1\n",
            "          Conv2d-181            [-1, 128, 8, 8]         147,584\n",
            "     BatchNorm2d-182            [-1, 128, 8, 8]             256\n",
            "           PReLU-183            [-1, 128, 8, 8]               1\n",
            "          Conv2d-184            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-185            [-1, 128, 8, 8]             256\n",
            "           PReLU-186            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-187            [-1, 128, 8, 8]               0\n",
            "           PReLU-188            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-189            [-1, 128, 8, 8]               0\n",
            "          Conv2d-190            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-191            [-1, 128, 8, 8]             256\n",
            "           PReLU-192            [-1, 128, 8, 8]               1\n",
            "          Conv2d-193            [-1, 128, 8, 8]         147,584\n",
            "     BatchNorm2d-194            [-1, 128, 8, 8]             256\n",
            "           PReLU-195            [-1, 128, 8, 8]               1\n",
            "          Conv2d-196            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-197            [-1, 128, 8, 8]             256\n",
            "           PReLU-198            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-199            [-1, 128, 8, 8]               0\n",
            "           PReLU-200            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-201            [-1, 128, 8, 8]               0\n",
            "          Conv2d-202            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-203            [-1, 128, 8, 8]             256\n",
            "           PReLU-204            [-1, 128, 8, 8]               1\n",
            "          Conv2d-205            [-1, 128, 8, 8]          82,048\n",
            "          Conv2d-206            [-1, 128, 8, 8]          82,048\n",
            "     BatchNorm2d-207            [-1, 128, 8, 8]             256\n",
            "           PReLU-208            [-1, 128, 8, 8]               1\n",
            "          Conv2d-209            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-210            [-1, 128, 8, 8]             256\n",
            "           PReLU-211            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-212            [-1, 128, 8, 8]               0\n",
            "           PReLU-213            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-214            [-1, 128, 8, 8]               0\n",
            "          Conv2d-215            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-216            [-1, 128, 8, 8]             256\n",
            "           PReLU-217            [-1, 128, 8, 8]               1\n",
            "          Conv2d-218            [-1, 128, 8, 8]         147,584\n",
            "     BatchNorm2d-219            [-1, 128, 8, 8]             256\n",
            "           PReLU-220            [-1, 128, 8, 8]               1\n",
            "          Conv2d-221            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-222            [-1, 128, 8, 8]             256\n",
            "           PReLU-223            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-224            [-1, 128, 8, 8]               0\n",
            "           PReLU-225            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-226            [-1, 128, 8, 8]               0\n",
            "          Conv2d-227            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-228            [-1, 128, 8, 8]             256\n",
            "           PReLU-229            [-1, 128, 8, 8]               1\n",
            "          Conv2d-230            [-1, 128, 8, 8]         147,584\n",
            "     BatchNorm2d-231            [-1, 128, 8, 8]             256\n",
            "           PReLU-232            [-1, 128, 8, 8]               1\n",
            "          Conv2d-233            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-234            [-1, 128, 8, 8]             256\n",
            "           PReLU-235            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-236            [-1, 128, 8, 8]               0\n",
            "           PReLU-237            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-238            [-1, 128, 8, 8]               0\n",
            "          Conv2d-239            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-240            [-1, 128, 8, 8]             256\n",
            "           PReLU-241            [-1, 128, 8, 8]               1\n",
            "          Conv2d-242            [-1, 128, 8, 8]         147,584\n",
            "     BatchNorm2d-243            [-1, 128, 8, 8]             256\n",
            "           PReLU-244            [-1, 128, 8, 8]               1\n",
            "          Conv2d-245            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-246            [-1, 128, 8, 8]             256\n",
            "           PReLU-247            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-248            [-1, 128, 8, 8]               0\n",
            "           PReLU-249            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-250            [-1, 128, 8, 8]               0\n",
            "          Conv2d-251            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-252            [-1, 128, 8, 8]             256\n",
            "           PReLU-253            [-1, 128, 8, 8]               1\n",
            "          Conv2d-254            [-1, 128, 8, 8]          82,048\n",
            "          Conv2d-255            [-1, 128, 8, 8]          82,048\n",
            "     BatchNorm2d-256            [-1, 128, 8, 8]             256\n",
            "           PReLU-257            [-1, 128, 8, 8]               1\n",
            "          Conv2d-258            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-259            [-1, 128, 8, 8]             256\n",
            "           PReLU-260            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-261            [-1, 128, 8, 8]               0\n",
            "           PReLU-262            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-263            [-1, 128, 8, 8]               0\n",
            "          Conv2d-264            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-265            [-1, 128, 8, 8]             256\n",
            "           PReLU-266            [-1, 128, 8, 8]               1\n",
            "          Conv2d-267            [-1, 128, 8, 8]         147,584\n",
            "     BatchNorm2d-268            [-1, 128, 8, 8]             256\n",
            "           PReLU-269            [-1, 128, 8, 8]               1\n",
            "          Conv2d-270            [-1, 128, 8, 8]          16,512\n",
            "     BatchNorm2d-271            [-1, 128, 8, 8]             256\n",
            "           PReLU-272            [-1, 128, 8, 8]               1\n",
            "       Dropout2d-273            [-1, 128, 8, 8]               0\n",
            "           PReLU-274            [-1, 128, 8, 8]               1\n",
            "BottleneckModule-275            [-1, 128, 8, 8]               0\n",
            "    ENet_Encoder-276            [-1, 128, 8, 8]               0\n",
            "          Conv2d-277             [-1, 64, 8, 8]           8,256\n",
            "     BatchNorm2d-278             [-1, 64, 8, 8]             128\n",
            "           PReLU-279             [-1, 64, 8, 8]               1\n",
            " ConvTranspose2d-280           [-1, 64, 16, 16]          16,448\n",
            "     BatchNorm2d-281           [-1, 64, 16, 16]             128\n",
            "           PReLU-282           [-1, 64, 16, 16]               1\n",
            "          Conv2d-283           [-1, 64, 16, 16]           4,160\n",
            "     BatchNorm2d-284           [-1, 64, 16, 16]             128\n",
            "           PReLU-285           [-1, 64, 16, 16]               1\n",
            "       Dropout2d-286           [-1, 64, 16, 16]               0\n",
            "          Conv2d-287             [-1, 64, 8, 8]           8,256\n",
            "     BatchNorm2d-288             [-1, 64, 8, 8]             128\n",
            "        Upsample-289           [-1, 64, 16, 16]               0\n",
            "           PReLU-290           [-1, 64, 16, 16]               1\n",
            "BottleneckModule-291           [-1, 64, 16, 16]               0\n",
            "          Conv2d-292           [-1, 64, 16, 16]           4,160\n",
            "     BatchNorm2d-293           [-1, 64, 16, 16]             128\n",
            "           PReLU-294           [-1, 64, 16, 16]               1\n",
            "          Conv2d-295           [-1, 64, 16, 16]          36,928\n",
            "     BatchNorm2d-296           [-1, 64, 16, 16]             128\n",
            "           PReLU-297           [-1, 64, 16, 16]               1\n",
            "          Conv2d-298           [-1, 64, 16, 16]           4,160\n",
            "     BatchNorm2d-299           [-1, 64, 16, 16]             128\n",
            "           PReLU-300           [-1, 64, 16, 16]               1\n",
            "       Dropout2d-301           [-1, 64, 16, 16]               0\n",
            "           PReLU-302           [-1, 64, 16, 16]               1\n",
            "BottleneckModule-303           [-1, 64, 16, 16]               0\n",
            "          Conv2d-304           [-1, 64, 16, 16]           4,160\n",
            "     BatchNorm2d-305           [-1, 64, 16, 16]             128\n",
            "           PReLU-306           [-1, 64, 16, 16]               1\n",
            "          Conv2d-307           [-1, 64, 16, 16]          36,928\n",
            "     BatchNorm2d-308           [-1, 64, 16, 16]             128\n",
            "           PReLU-309           [-1, 64, 16, 16]               1\n",
            "          Conv2d-310           [-1, 64, 16, 16]           4,160\n",
            "     BatchNorm2d-311           [-1, 64, 16, 16]             128\n",
            "           PReLU-312           [-1, 64, 16, 16]               1\n",
            "       Dropout2d-313           [-1, 64, 16, 16]               0\n",
            "           PReLU-314           [-1, 64, 16, 16]               1\n",
            "BottleneckModule-315           [-1, 64, 16, 16]               0\n",
            "          Conv2d-316           [-1, 16, 16, 16]           1,040\n",
            "     BatchNorm2d-317           [-1, 16, 16, 16]              32\n",
            "           PReLU-318           [-1, 16, 16, 16]               1\n",
            " ConvTranspose2d-319           [-1, 16, 32, 32]           1,040\n",
            "     BatchNorm2d-320           [-1, 16, 32, 32]              32\n",
            "           PReLU-321           [-1, 16, 32, 32]               1\n",
            "          Conv2d-322           [-1, 16, 32, 32]             272\n",
            "     BatchNorm2d-323           [-1, 16, 32, 32]              32\n",
            "           PReLU-324           [-1, 16, 32, 32]               1\n",
            "       Dropout2d-325           [-1, 16, 32, 32]               0\n",
            "          Conv2d-326           [-1, 16, 16, 16]           1,040\n",
            "     BatchNorm2d-327           [-1, 16, 16, 16]              32\n",
            "        Upsample-328           [-1, 16, 32, 32]               0\n",
            "           PReLU-329           [-1, 16, 32, 32]               1\n",
            "BottleneckModule-330           [-1, 16, 32, 32]               0\n",
            "          Conv2d-331           [-1, 16, 32, 32]             272\n",
            "     BatchNorm2d-332           [-1, 16, 32, 32]              32\n",
            "           PReLU-333           [-1, 16, 32, 32]               1\n",
            "          Conv2d-334           [-1, 16, 32, 32]           2,320\n",
            "     BatchNorm2d-335           [-1, 16, 32, 32]              32\n",
            "           PReLU-336           [-1, 16, 32, 32]               1\n",
            "          Conv2d-337           [-1, 16, 32, 32]             272\n",
            "     BatchNorm2d-338           [-1, 16, 32, 32]              32\n",
            "           PReLU-339           [-1, 16, 32, 32]               1\n",
            "       Dropout2d-340           [-1, 16, 32, 32]               0\n",
            "           PReLU-341           [-1, 16, 32, 32]               1\n",
            "BottleneckModule-342           [-1, 16, 32, 32]               0\n",
            " ConvTranspose2d-343            [-1, 2, 64, 64]             130\n",
            "    ENet_Decoder-344            [-1, 2, 64, 64]               0\n",
            "          Conv2d-345             [-1, 64, 8, 8]           8,256\n",
            "     BatchNorm2d-346             [-1, 64, 8, 8]             128\n",
            "           PReLU-347             [-1, 64, 8, 8]               1\n",
            " ConvTranspose2d-348           [-1, 64, 16, 16]          16,448\n",
            "     BatchNorm2d-349           [-1, 64, 16, 16]             128\n",
            "           PReLU-350           [-1, 64, 16, 16]               1\n",
            "          Conv2d-351           [-1, 64, 16, 16]           4,160\n",
            "     BatchNorm2d-352           [-1, 64, 16, 16]             128\n",
            "           PReLU-353           [-1, 64, 16, 16]               1\n",
            "       Dropout2d-354           [-1, 64, 16, 16]               0\n",
            "          Conv2d-355             [-1, 64, 8, 8]           8,256\n",
            "     BatchNorm2d-356             [-1, 64, 8, 8]             128\n",
            "        Upsample-357           [-1, 64, 16, 16]               0\n",
            "           PReLU-358           [-1, 64, 16, 16]               1\n",
            "BottleneckModule-359           [-1, 64, 16, 16]               0\n",
            "          Conv2d-360           [-1, 64, 16, 16]           4,160\n",
            "     BatchNorm2d-361           [-1, 64, 16, 16]             128\n",
            "           PReLU-362           [-1, 64, 16, 16]               1\n",
            "          Conv2d-363           [-1, 64, 16, 16]          36,928\n",
            "     BatchNorm2d-364           [-1, 64, 16, 16]             128\n",
            "           PReLU-365           [-1, 64, 16, 16]               1\n",
            "          Conv2d-366           [-1, 64, 16, 16]           4,160\n",
            "     BatchNorm2d-367           [-1, 64, 16, 16]             128\n",
            "           PReLU-368           [-1, 64, 16, 16]               1\n",
            "       Dropout2d-369           [-1, 64, 16, 16]               0\n",
            "           PReLU-370           [-1, 64, 16, 16]               1\n",
            "BottleneckModule-371           [-1, 64, 16, 16]               0\n",
            "          Conv2d-372           [-1, 64, 16, 16]           4,160\n",
            "     BatchNorm2d-373           [-1, 64, 16, 16]             128\n",
            "           PReLU-374           [-1, 64, 16, 16]               1\n",
            "          Conv2d-375           [-1, 64, 16, 16]          36,928\n",
            "     BatchNorm2d-376           [-1, 64, 16, 16]             128\n",
            "           PReLU-377           [-1, 64, 16, 16]               1\n",
            "          Conv2d-378           [-1, 64, 16, 16]           4,160\n",
            "     BatchNorm2d-379           [-1, 64, 16, 16]             128\n",
            "           PReLU-380           [-1, 64, 16, 16]               1\n",
            "       Dropout2d-381           [-1, 64, 16, 16]               0\n",
            "           PReLU-382           [-1, 64, 16, 16]               1\n",
            "BottleneckModule-383           [-1, 64, 16, 16]               0\n",
            "          Conv2d-384           [-1, 16, 16, 16]           1,040\n",
            "     BatchNorm2d-385           [-1, 16, 16, 16]              32\n",
            "           PReLU-386           [-1, 16, 16, 16]               1\n",
            " ConvTranspose2d-387           [-1, 16, 32, 32]           1,040\n",
            "     BatchNorm2d-388           [-1, 16, 32, 32]              32\n",
            "           PReLU-389           [-1, 16, 32, 32]               1\n",
            "          Conv2d-390           [-1, 16, 32, 32]             272\n",
            "     BatchNorm2d-391           [-1, 16, 32, 32]              32\n",
            "           PReLU-392           [-1, 16, 32, 32]               1\n",
            "       Dropout2d-393           [-1, 16, 32, 32]               0\n",
            "          Conv2d-394           [-1, 16, 16, 16]           1,040\n",
            "     BatchNorm2d-395           [-1, 16, 16, 16]              32\n",
            "        Upsample-396           [-1, 16, 32, 32]               0\n",
            "           PReLU-397           [-1, 16, 32, 32]               1\n",
            "BottleneckModule-398           [-1, 16, 32, 32]               0\n",
            "          Conv2d-399           [-1, 16, 32, 32]             272\n",
            "     BatchNorm2d-400           [-1, 16, 32, 32]              32\n",
            "           PReLU-401           [-1, 16, 32, 32]               1\n",
            "          Conv2d-402           [-1, 16, 32, 32]           2,320\n",
            "     BatchNorm2d-403           [-1, 16, 32, 32]              32\n",
            "           PReLU-404           [-1, 16, 32, 32]               1\n",
            "          Conv2d-405           [-1, 16, 32, 32]             272\n",
            "     BatchNorm2d-406           [-1, 16, 32, 32]              32\n",
            "           PReLU-407           [-1, 16, 32, 32]               1\n",
            "       Dropout2d-408           [-1, 16, 32, 32]               0\n",
            "           PReLU-409           [-1, 16, 32, 32]               1\n",
            "BottleneckModule-410           [-1, 16, 32, 32]               0\n",
            " ConvTranspose2d-411            [-1, 3, 64, 64]             195\n",
            "    ENet_Decoder-412            [-1, 3, 64, 64]               0\n",
            "         Sigmoid-413            [-1, 3, 64, 64]               0\n",
            "================================================================\n",
            "Total params: 3,665,580\n",
            "Trainable params: 3,665,580\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 36.11\n",
            "Params size (MB): 13.98\n",
            "Estimated Total Size (MB): 50.14\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size = (3, 64, 64), batch_size = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/jetson/lanenet_ws/src\n"
          ]
        }
      ],
      "source": [
        "cd src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['_encoder.initial_block.conv.0.bias', '_encoder.initial_block.conv.1.bias', '_encoder.initial_block.conv.1.running_mean', '_encoder.initial_block.conv.1.running_var', '_encoder.bottleneck1_0.conv.0.bias', '_encoder.bottleneck1_0.conv.1.bias', '_encoder.bottleneck1_0.conv.1.running_mean', '_encoder.bottleneck1_0.conv.1.running_var', '_encoder.bottleneck1_0.conv.3.bias', '_encoder.bottleneck1_0.conv.4.bias', '_encoder.bottleneck1_0.conv.4.running_mean', '_encoder.bottleneck1_0.conv.4.running_var', '_encoder.bottleneck1_0.conv.6.bias', '_encoder.bottleneck1_0.conv.7.bias', '_encoder.bottleneck1_0.conv.7.running_mean', '_encoder.bottleneck1_0.conv.7.running_var', '_encoder.bottleneck1_1.conv.0.bias', '_encoder.bottleneck1_1.conv.1.bias', '_encoder.bottleneck1_1.conv.1.running_mean', '_encoder.bottleneck1_1.conv.1.running_var', '_encoder.bottleneck1_1.conv.3.bias', '_encoder.bottleneck1_1.conv.4.bias', '_encoder.bottleneck1_1.conv.4.running_mean', '_encoder.bottleneck1_1.conv.4.running_var', '_encoder.bottleneck1_1.conv.6.bias', '_encoder.bottleneck1_1.conv.7.bias', '_encoder.bottleneck1_1.conv.7.running_mean', '_encoder.bottleneck1_1.conv.7.running_var', '_encoder.bottleneck1_2.conv.0.bias', '_encoder.bottleneck1_2.conv.1.bias', '_encoder.bottleneck1_2.conv.1.running_mean', '_encoder.bottleneck1_2.conv.1.running_var', '_encoder.bottleneck1_2.conv.3.bias', '_encoder.bottleneck1_2.conv.4.bias', '_encoder.bottleneck1_2.conv.4.running_mean', '_encoder.bottleneck1_2.conv.4.running_var', '_encoder.bottleneck1_2.conv.6.bias', '_encoder.bottleneck1_2.conv.7.bias', '_encoder.bottleneck1_2.conv.7.running_mean', '_encoder.bottleneck1_2.conv.7.running_var', '_encoder.bottleneck1_3.conv.0.bias', '_encoder.bottleneck1_3.conv.1.bias', '_encoder.bottleneck1_3.conv.1.running_mean', '_encoder.bottleneck1_3.conv.1.running_var', '_encoder.bottleneck1_3.conv.3.bias', '_encoder.bottleneck1_3.conv.4.bias', '_encoder.bottleneck1_3.conv.4.running_mean', '_encoder.bottleneck1_3.conv.4.running_var', '_encoder.bottleneck1_3.conv.6.bias', '_encoder.bottleneck1_3.conv.7.bias', '_encoder.bottleneck1_3.conv.7.running_mean', '_encoder.bottleneck1_3.conv.7.running_var', '_encoder.bottleneck1_4.conv.0.bias', '_encoder.bottleneck1_4.conv.1.bias', '_encoder.bottleneck1_4.conv.1.running_mean', '_encoder.bottleneck1_4.conv.1.running_var', '_encoder.bottleneck1_4.conv.3.bias', '_encoder.bottleneck1_4.conv.4.bias', '_encoder.bottleneck1_4.conv.4.running_mean', '_encoder.bottleneck1_4.conv.4.running_var', '_encoder.bottleneck1_4.conv.6.bias', '_encoder.bottleneck1_4.conv.7.bias', '_encoder.bottleneck1_4.conv.7.running_mean', '_encoder.bottleneck1_4.conv.7.running_var', '_encoder.bottleneck2_0.conv.0.bias', '_encoder.bottleneck2_0.conv.1.bias', '_encoder.bottleneck2_0.conv.1.running_mean', '_encoder.bottleneck2_0.conv.1.running_var', '_encoder.bottleneck2_0.conv.3.bias', '_encoder.bottleneck2_0.conv.4.bias', '_encoder.bottleneck2_0.conv.4.running_mean', '_encoder.bottleneck2_0.conv.4.running_var', '_encoder.bottleneck2_0.conv.6.bias', '_encoder.bottleneck2_0.conv.7.bias', '_encoder.bottleneck2_0.conv.7.running_mean', '_encoder.bottleneck2_0.conv.7.running_var', '_encoder.bottleneck2_1.conv.0.bias', '_encoder.bottleneck2_1.conv.1.bias', '_encoder.bottleneck2_1.conv.1.running_mean', '_encoder.bottleneck2_1.conv.1.running_var', '_encoder.bottleneck2_1.conv.3.bias', '_encoder.bottleneck2_1.conv.4.bias', '_encoder.bottleneck2_1.conv.4.running_mean', '_encoder.bottleneck2_1.conv.4.running_var', '_encoder.bottleneck2_1.conv.6.bias', '_encoder.bottleneck2_1.conv.7.bias', '_encoder.bottleneck2_1.conv.7.running_mean', '_encoder.bottleneck2_1.conv.7.running_var', '_encoder.bottleneck2_2.conv.0.bias', '_encoder.bottleneck2_2.conv.1.bias', '_encoder.bottleneck2_2.conv.1.running_mean', '_encoder.bottleneck2_2.conv.1.running_var', '_encoder.bottleneck2_2.conv.3.bias', '_encoder.bottleneck2_2.conv.4.bias', '_encoder.bottleneck2_2.conv.4.running_mean', '_encoder.bottleneck2_2.conv.4.running_var', '_encoder.bottleneck2_2.conv.6.bias', '_encoder.bottleneck2_2.conv.7.bias', '_encoder.bottleneck2_2.conv.7.running_mean', '_encoder.bottleneck2_2.conv.7.running_var', '_encoder.bottleneck2_3.conv.0.bias', '_encoder.bottleneck2_3.conv.1.bias', '_encoder.bottleneck2_3.conv.1.running_mean', '_encoder.bottleneck2_3.conv.1.running_var', '_encoder.bottleneck2_3.conv.3.bias', '_encoder.bottleneck2_3.conv.4.bias', '_encoder.bottleneck2_3.conv.5.bias', '_encoder.bottleneck2_3.conv.5.running_mean', '_encoder.bottleneck2_3.conv.5.running_var', '_encoder.bottleneck2_3.conv.7.bias', '_encoder.bottleneck2_3.conv.8.bias', '_encoder.bottleneck2_3.conv.8.running_mean', '_encoder.bottleneck2_3.conv.8.running_var', '_encoder.bottleneck2_4.conv.0.bias', '_encoder.bottleneck2_4.conv.1.bias', '_encoder.bottleneck2_4.conv.1.running_mean', '_encoder.bottleneck2_4.conv.1.running_var', '_encoder.bottleneck2_4.conv.3.bias', '_encoder.bottleneck2_4.conv.4.bias', '_encoder.bottleneck2_4.conv.4.running_mean', '_encoder.bottleneck2_4.conv.4.running_var', '_encoder.bottleneck2_4.conv.6.bias', '_encoder.bottleneck2_4.conv.7.bias', '_encoder.bottleneck2_4.conv.7.running_mean', '_encoder.bottleneck2_4.conv.7.running_var', '_encoder.bottleneck2_5.conv.0.bias', '_encoder.bottleneck2_5.conv.1.bias', '_encoder.bottleneck2_5.conv.1.running_mean', '_encoder.bottleneck2_5.conv.1.running_var', '_encoder.bottleneck2_5.conv.3.bias', '_encoder.bottleneck2_5.conv.4.bias', '_encoder.bottleneck2_5.conv.4.running_mean', '_encoder.bottleneck2_5.conv.4.running_var', '_encoder.bottleneck2_5.conv.6.bias', '_encoder.bottleneck2_5.conv.7.bias', '_encoder.bottleneck2_5.conv.7.running_mean', '_encoder.bottleneck2_5.conv.7.running_var', '_encoder.bottleneck2_6.conv.0.bias', '_encoder.bottleneck2_6.conv.1.bias', '_encoder.bottleneck2_6.conv.1.running_mean', '_encoder.bottleneck2_6.conv.1.running_var', '_encoder.bottleneck2_6.conv.3.bias', '_encoder.bottleneck2_6.conv.4.bias', '_encoder.bottleneck2_6.conv.4.running_mean', '_encoder.bottleneck2_6.conv.4.running_var', '_encoder.bottleneck2_6.conv.6.bias', '_encoder.bottleneck2_6.conv.7.bias', '_encoder.bottleneck2_6.conv.7.running_mean', '_encoder.bottleneck2_6.conv.7.running_var', '_encoder.bottleneck2_7.conv.0.bias', '_encoder.bottleneck2_7.conv.1.bias', '_encoder.bottleneck2_7.conv.1.running_mean', '_encoder.bottleneck2_7.conv.1.running_var', '_encoder.bottleneck2_7.conv.3.bias', '_encoder.bottleneck2_7.conv.4.bias', '_encoder.bottleneck2_7.conv.5.bias', '_encoder.bottleneck2_7.conv.5.running_mean', '_encoder.bottleneck2_7.conv.5.running_var', '_encoder.bottleneck2_7.conv.7.bias', '_encoder.bottleneck2_7.conv.8.bias', '_encoder.bottleneck2_7.conv.8.running_mean', '_encoder.bottleneck2_7.conv.8.running_var', '_encoder.bottleneck2_8.conv.0.bias', '_encoder.bottleneck2_8.conv.1.bias', '_encoder.bottleneck2_8.conv.1.running_mean', '_encoder.bottleneck2_8.conv.1.running_var', '_encoder.bottleneck2_8.conv.3.bias', '_encoder.bottleneck2_8.conv.4.bias', '_encoder.bottleneck2_8.conv.4.running_mean', '_encoder.bottleneck2_8.conv.4.running_var', '_encoder.bottleneck2_8.conv.6.bias', '_encoder.bottleneck2_8.conv.7.bias', '_encoder.bottleneck2_8.conv.7.running_mean', '_encoder.bottleneck2_8.conv.7.running_var', '_encoder.bottleneck3_0.conv.0.bias', '_encoder.bottleneck3_0.conv.1.bias', '_encoder.bottleneck3_0.conv.1.running_mean', '_encoder.bottleneck3_0.conv.1.running_var', '_encoder.bottleneck3_0.conv.3.bias', '_encoder.bottleneck3_0.conv.4.bias', '_encoder.bottleneck3_0.conv.4.running_mean', '_encoder.bottleneck3_0.conv.4.running_var', '_encoder.bottleneck3_0.conv.6.bias', '_encoder.bottleneck3_0.conv.7.bias', '_encoder.bottleneck3_0.conv.7.running_mean', '_encoder.bottleneck3_0.conv.7.running_var', '_encoder.bottleneck3_1.conv.0.bias', '_encoder.bottleneck3_1.conv.1.bias', '_encoder.bottleneck3_1.conv.1.running_mean', '_encoder.bottleneck3_1.conv.1.running_var', '_encoder.bottleneck3_1.conv.3.bias', '_encoder.bottleneck3_1.conv.4.bias', '_encoder.bottleneck3_1.conv.4.running_mean', '_encoder.bottleneck3_1.conv.4.running_var', '_encoder.bottleneck3_1.conv.6.bias', '_encoder.bottleneck3_1.conv.7.bias', '_encoder.bottleneck3_1.conv.7.running_mean', '_encoder.bottleneck3_1.conv.7.running_var', '_encoder.bottleneck3_2.conv.0.bias', '_encoder.bottleneck3_2.conv.1.bias', '_encoder.bottleneck3_2.conv.1.running_mean', '_encoder.bottleneck3_2.conv.1.running_var', '_encoder.bottleneck3_2.conv.3.bias', '_encoder.bottleneck3_2.conv.4.bias', '_encoder.bottleneck3_2.conv.5.bias', '_encoder.bottleneck3_2.conv.5.running_mean', '_encoder.bottleneck3_2.conv.5.running_var', '_encoder.bottleneck3_2.conv.7.bias', '_encoder.bottleneck3_2.conv.8.bias', '_encoder.bottleneck3_2.conv.8.running_mean', '_encoder.bottleneck3_2.conv.8.running_var', '_encoder.bottleneck3_3.conv.0.bias', '_encoder.bottleneck3_3.conv.1.bias', '_encoder.bottleneck3_3.conv.1.running_mean', '_encoder.bottleneck3_3.conv.1.running_var', '_encoder.bottleneck3_3.conv.3.bias', '_encoder.bottleneck3_3.conv.4.bias', '_encoder.bottleneck3_3.conv.4.running_mean', '_encoder.bottleneck3_3.conv.4.running_var', '_encoder.bottleneck3_3.conv.6.bias', '_encoder.bottleneck3_3.conv.7.bias', '_encoder.bottleneck3_3.conv.7.running_mean', '_encoder.bottleneck3_3.conv.7.running_var', '_encoder.bottleneck3_4.conv.0.bias', '_encoder.bottleneck3_4.conv.1.bias', '_encoder.bottleneck3_4.conv.1.running_mean', '_encoder.bottleneck3_4.conv.1.running_var', '_encoder.bottleneck3_4.conv.3.bias', '_encoder.bottleneck3_4.conv.4.bias', '_encoder.bottleneck3_4.conv.4.running_mean', '_encoder.bottleneck3_4.conv.4.running_var', '_encoder.bottleneck3_4.conv.6.bias', '_encoder.bottleneck3_4.conv.7.bias', '_encoder.bottleneck3_4.conv.7.running_mean', '_encoder.bottleneck3_4.conv.7.running_var', '_encoder.bottleneck3_5.conv.0.bias', '_encoder.bottleneck3_5.conv.1.bias', '_encoder.bottleneck3_5.conv.1.running_mean', '_encoder.bottleneck3_5.conv.1.running_var', '_encoder.bottleneck3_5.conv.3.bias', '_encoder.bottleneck3_5.conv.4.bias', '_encoder.bottleneck3_5.conv.4.running_mean', '_encoder.bottleneck3_5.conv.4.running_var', '_encoder.bottleneck3_5.conv.6.bias', '_encoder.bottleneck3_5.conv.7.bias', '_encoder.bottleneck3_5.conv.7.running_mean', '_encoder.bottleneck3_5.conv.7.running_var', '_encoder.bottleneck3_6.conv.0.bias', '_encoder.bottleneck3_6.conv.1.bias', '_encoder.bottleneck3_6.conv.1.running_mean', '_encoder.bottleneck3_6.conv.1.running_var', '_encoder.bottleneck3_6.conv.3.bias', '_encoder.bottleneck3_6.conv.4.bias', '_encoder.bottleneck3_6.conv.5.bias', '_encoder.bottleneck3_6.conv.5.running_mean', '_encoder.bottleneck3_6.conv.5.running_var', '_encoder.bottleneck3_6.conv.7.bias', '_encoder.bottleneck3_6.conv.8.bias', '_encoder.bottleneck3_6.conv.8.running_mean', '_encoder.bottleneck3_6.conv.8.running_var', '_encoder.bottleneck3_7.conv.0.bias', '_encoder.bottleneck3_7.conv.1.bias', '_encoder.bottleneck3_7.conv.1.running_mean', '_encoder.bottleneck3_7.conv.1.running_var', '_encoder.bottleneck3_7.conv.3.bias', '_encoder.bottleneck3_7.conv.4.bias', '_encoder.bottleneck3_7.conv.4.running_mean', '_encoder.bottleneck3_7.conv.4.running_var', '_encoder.bottleneck3_7.conv.6.bias', '_encoder.bottleneck3_7.conv.7.bias', '_encoder.bottleneck3_7.conv.7.running_mean', '_encoder.bottleneck3_7.conv.7.running_var', '_decoder_binary.bottleneck4_0.maxunpool.0.bias', '_decoder_binary.bottleneck4_0.maxunpool.1.bias', '_decoder_binary.bottleneck4_0.maxunpool.1.running_mean', '_decoder_binary.bottleneck4_0.maxunpool.1.running_var', '_decoder_binary.bottleneck4_0.conv.0.bias', '_decoder_binary.bottleneck4_0.conv.1.bias', '_decoder_binary.bottleneck4_0.conv.1.running_mean', '_decoder_binary.bottleneck4_0.conv.1.running_var', '_decoder_binary.bottleneck4_0.conv.3.bias', '_decoder_binary.bottleneck4_0.conv.4.bias', '_decoder_binary.bottleneck4_0.conv.4.running_mean', '_decoder_binary.bottleneck4_0.conv.4.running_var', '_decoder_binary.bottleneck4_0.conv.6.bias', '_decoder_binary.bottleneck4_0.conv.7.bias', '_decoder_binary.bottleneck4_0.conv.7.running_mean', '_decoder_binary.bottleneck4_0.conv.7.running_var', '_decoder_binary.bottleneck4_1.conv.0.bias', '_decoder_binary.bottleneck4_1.conv.1.bias', '_decoder_binary.bottleneck4_1.conv.1.running_mean', '_decoder_binary.bottleneck4_1.conv.1.running_var', '_decoder_binary.bottleneck4_1.conv.3.bias', '_decoder_binary.bottleneck4_1.conv.4.bias', '_decoder_binary.bottleneck4_1.conv.4.running_mean', '_decoder_binary.bottleneck4_1.conv.4.running_var', '_decoder_binary.bottleneck4_1.conv.6.bias', '_decoder_binary.bottleneck4_1.conv.7.bias', '_decoder_binary.bottleneck4_1.conv.7.running_mean', '_decoder_binary.bottleneck4_1.conv.7.running_var', '_decoder_binary.bottleneck4_2.conv.0.bias', '_decoder_binary.bottleneck4_2.conv.1.bias', '_decoder_binary.bottleneck4_2.conv.1.running_mean', '_decoder_binary.bottleneck4_2.conv.1.running_var', '_decoder_binary.bottleneck4_2.conv.3.bias', '_decoder_binary.bottleneck4_2.conv.4.bias', '_decoder_binary.bottleneck4_2.conv.4.running_mean', '_decoder_binary.bottleneck4_2.conv.4.running_var', '_decoder_binary.bottleneck4_2.conv.6.bias', '_decoder_binary.bottleneck4_2.conv.7.bias', '_decoder_binary.bottleneck4_2.conv.7.running_mean', '_decoder_binary.bottleneck4_2.conv.7.running_var', '_decoder_binary.bottleneck5_0.maxunpool.0.bias', '_decoder_binary.bottleneck5_0.maxunpool.1.bias', '_decoder_binary.bottleneck5_0.maxunpool.1.running_mean', '_decoder_binary.bottleneck5_0.maxunpool.1.running_var', '_decoder_binary.bottleneck5_0.conv.0.bias', '_decoder_binary.bottleneck5_0.conv.1.bias', '_decoder_binary.bottleneck5_0.conv.1.running_mean', '_decoder_binary.bottleneck5_0.conv.1.running_var', '_decoder_binary.bottleneck5_0.conv.3.bias', '_decoder_binary.bottleneck5_0.conv.4.bias', '_decoder_binary.bottleneck5_0.conv.4.running_mean', '_decoder_binary.bottleneck5_0.conv.4.running_var', '_decoder_binary.bottleneck5_0.conv.6.bias', '_decoder_binary.bottleneck5_0.conv.7.bias', '_decoder_binary.bottleneck5_0.conv.7.running_mean', '_decoder_binary.bottleneck5_0.conv.7.running_var', '_decoder_binary.bottleneck5_1.conv.0.bias', '_decoder_binary.bottleneck5_1.conv.1.bias', '_decoder_binary.bottleneck5_1.conv.1.running_mean', '_decoder_binary.bottleneck5_1.conv.1.running_var', '_decoder_binary.bottleneck5_1.conv.3.bias', '_decoder_binary.bottleneck5_1.conv.4.bias', '_decoder_binary.bottleneck5_1.conv.4.running_mean', '_decoder_binary.bottleneck5_1.conv.4.running_var', '_decoder_binary.bottleneck5_1.conv.6.bias', '_decoder_binary.bottleneck5_1.conv.7.bias', '_decoder_binary.bottleneck5_1.conv.7.running_mean', '_decoder_binary.bottleneck5_1.conv.7.running_var', '_decoder_binary.fullconv.bias', '_decoder_instance.bottleneck4_0.maxunpool.0.bias', '_decoder_instance.bottleneck4_0.maxunpool.1.bias', '_decoder_instance.bottleneck4_0.maxunpool.1.running_mean', '_decoder_instance.bottleneck4_0.maxunpool.1.running_var', '_decoder_instance.bottleneck4_0.conv.0.bias', '_decoder_instance.bottleneck4_0.conv.1.bias', '_decoder_instance.bottleneck4_0.conv.1.running_mean', '_decoder_instance.bottleneck4_0.conv.1.running_var', '_decoder_instance.bottleneck4_0.conv.3.bias', '_decoder_instance.bottleneck4_0.conv.4.bias', '_decoder_instance.bottleneck4_0.conv.4.running_mean', '_decoder_instance.bottleneck4_0.conv.4.running_var', '_decoder_instance.bottleneck4_0.conv.6.bias', '_decoder_instance.bottleneck4_0.conv.7.bias', '_decoder_instance.bottleneck4_0.conv.7.running_mean', '_decoder_instance.bottleneck4_0.conv.7.running_var', '_decoder_instance.bottleneck4_1.conv.0.bias', '_decoder_instance.bottleneck4_1.conv.1.bias', '_decoder_instance.bottleneck4_1.conv.1.running_mean', '_decoder_instance.bottleneck4_1.conv.1.running_var', '_decoder_instance.bottleneck4_1.conv.3.bias', '_decoder_instance.bottleneck4_1.conv.4.bias', '_decoder_instance.bottleneck4_1.conv.4.running_mean', '_decoder_instance.bottleneck4_1.conv.4.running_var', '_decoder_instance.bottleneck4_1.conv.6.bias', '_decoder_instance.bottleneck4_1.conv.7.bias', '_decoder_instance.bottleneck4_1.conv.7.running_mean', '_decoder_instance.bottleneck4_1.conv.7.running_var', '_decoder_instance.bottleneck4_2.conv.0.bias', '_decoder_instance.bottleneck4_2.conv.1.bias', '_decoder_instance.bottleneck4_2.conv.1.running_mean', '_decoder_instance.bottleneck4_2.conv.1.running_var', '_decoder_instance.bottleneck4_2.conv.3.bias', '_decoder_instance.bottleneck4_2.conv.4.bias', '_decoder_instance.bottleneck4_2.conv.4.running_mean', '_decoder_instance.bottleneck4_2.conv.4.running_var', '_decoder_instance.bottleneck4_2.conv.6.bias', '_decoder_instance.bottleneck4_2.conv.7.bias', '_decoder_instance.bottleneck4_2.conv.7.running_mean', '_decoder_instance.bottleneck4_2.conv.7.running_var', '_decoder_instance.bottleneck5_0.maxunpool.0.bias', '_decoder_instance.bottleneck5_0.maxunpool.1.bias', '_decoder_instance.bottleneck5_0.maxunpool.1.running_mean', '_decoder_instance.bottleneck5_0.maxunpool.1.running_var', '_decoder_instance.bottleneck5_0.conv.0.bias', '_decoder_instance.bottleneck5_0.conv.1.bias', '_decoder_instance.bottleneck5_0.conv.1.running_mean', '_decoder_instance.bottleneck5_0.conv.1.running_var', '_decoder_instance.bottleneck5_0.conv.3.bias', '_decoder_instance.bottleneck5_0.conv.4.bias', '_decoder_instance.bottleneck5_0.conv.4.running_mean', '_decoder_instance.bottleneck5_0.conv.4.running_var', '_decoder_instance.bottleneck5_0.conv.6.bias', '_decoder_instance.bottleneck5_0.conv.7.bias', '_decoder_instance.bottleneck5_0.conv.7.running_mean', '_decoder_instance.bottleneck5_0.conv.7.running_var', '_decoder_instance.bottleneck5_1.conv.0.bias', '_decoder_instance.bottleneck5_1.conv.1.bias', '_decoder_instance.bottleneck5_1.conv.1.running_mean', '_decoder_instance.bottleneck5_1.conv.1.running_var', '_decoder_instance.bottleneck5_1.conv.3.bias', '_decoder_instance.bottleneck5_1.conv.4.bias', '_decoder_instance.bottleneck5_1.conv.4.running_mean', '_decoder_instance.bottleneck5_1.conv.4.running_var', '_decoder_instance.bottleneck5_1.conv.6.bias', '_decoder_instance.bottleneck5_1.conv.7.bias', '_decoder_instance.bottleneck5_1.conv.7.running_mean', '_decoder_instance.bottleneck5_1.conv.7.running_var', '_decoder_instance.fullconv.bias'], unexpected_keys=[])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the model and extract weights\n",
        "import os \n",
        "\n",
        "checkpoint_path = os.path.join(\"model_weights_only.pth\")\n",
        "model.load_state_dict(torch.load(checkpoint_path), strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from model.lanenet.LaneNet import LaneNet\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "from model.utils.cli_helper_eval import parse_args\n",
        "from model.eval_function import Eval_Score\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Grayscale(3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def load_test_data(img_path, transform):\n",
        "    img = Image.open(img_path)\n",
        "    img = transform(img)\n",
        "    return img\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "img_path = os.path.join(\"lanenet-lane-detection-pytorch\",\"data\",\"source_image\", \"input.jpg\")\n",
        "resize_height = 0\n",
        "resize_width = 0\n",
        "\n",
        "model.to(DEVICE)\n",
        "\n",
        "dummy_input = load_test_data(img_path, data_transform).to(DEVICE)\n",
        "dummy_input = torch.unsqueeze(dummy_input, dim=0)\n",
        "outputs = model(dummy_input)\n",
        "\n",
        "instance_pred = torch.squeeze(outputs['instance_seg_logits'].detach().to('cpu')).numpy() * 255\n",
        "binary_pred = torch.squeeze(outputs['binary_seg_pred']).to('cpu').numpy() * 255\n",
        "\n",
        "color = \"output.jpg\"\n",
        "val = instance_pred.transpose((1, 2, 0))\n",
        "\n",
        "binary =\"binary.jpg\"\n",
        "cv2.imwrite(path, val)\n",
        "cv2.imwrite(binary, binary_pred)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
